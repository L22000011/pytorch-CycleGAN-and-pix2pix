import os
import torch
import numpy as np
from tqdm import tqdm
from PIL import Image
from torch.utils.data import DataLoader, TensorDataset
from torchvision import transforms
from torchvision.models import inception_v3
from scipy import linalg
import torch.nn as nn

# ==============================================
# é…ç½®
# ==============================================
# base_dir = r"E:\Deskbook\pytorch-CycleGAN-and-pix2pix_multi\results\cyc_roi\organized"
base_dir = r"E:\Deskbook\pytorch-CycleGAN-and-pix2pix_multi\results\cyc_edge\organized"
pairs = [
    ("fake_A", "real_A"),
    ("rec_A", "real_A"),
    ("fake_B", "real_B"),
    ("rec_B", "real_B"),
]
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")

# ==============================================
# å›¾åƒé¢„å¤„ç†
# ==============================================
transform = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                         std=[0.5, 0.5, 0.5])
])

# ==============================================
# åŠ è½½å›¾åƒå‡½æ•°
# ==============================================
def load_images_from_folder(folder, transform):
    imgs = []
    for filename in sorted(os.listdir(folder)):
        path = os.path.join(folder, filename)
        if os.path.isfile(path):
            try:
                img = Image.open(path).convert("RGB")
                imgs.append(transform(img))
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡ {filename}: {e}")
    return torch.stack(imgs)

# ==============================================
# è·å– InceptionV3 çš„ pool3 ç‰¹å¾ï¼ˆ2048ç»´ï¼‰
# ==============================================
class InceptionV3Features(nn.Module):
    def __init__(self):
        super().__init__()
        inception = inception_v3(weights="IMAGENET1K_V1", aux_logits=True)
        # ä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†ï¼Œä¸åŒ…æ‹¬åˆ†ç±»å¤´
        self.features = nn.Sequential(
            inception.Conv2d_1a_3x3,
            inception.Conv2d_2a_3x3,
            inception.Conv2d_2b_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2),
            inception.Conv2d_3b_1x1,
            inception.Conv2d_4a_3x3,
            nn.MaxPool2d(kernel_size=3, stride=2),
            inception.Mixed_5b,
            inception.Mixed_5c,
            inception.Mixed_5d,
            inception.Mixed_6a,
            inception.Mixed_6b,
            inception.Mixed_6c,
            inception.Mixed_6d,
            inception.Mixed_6e,
            inception.Mixed_7a,
            inception.Mixed_7b,
            inception.Mixed_7c,
            nn.AdaptiveAvgPool2d((1, 1)),
        )

    def forward(self, x):
        # è¿”å› flatten åçš„ç‰¹å¾
        features = self.features(x)
        return features.view(features.size(0), -1)


# ==============================================
# æå–ç‰¹å¾
# ==============================================
def get_features(model, dataloader, device):
    model.eval()
    feats = []
    with torch.no_grad():
        for (x,) in tqdm(dataloader, desc="æå–ç‰¹å¾ä¸­", leave=False):
            x = x.to(device)
            feat = model(x)
            feats.append(feat.cpu().numpy())
    return np.concatenate(feats, axis=0)

# ==============================================
# è®¡ç®—FID
# ==============================================
def calculate_fid(mu1, sigma1, mu2, sigma2, eps=1e-6):
    diff = mu1 - mu2
    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)
    if np.iscomplexobj(covmean):
        covmean = covmean.real
    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2.0 * covmean)
    return float(fid)

# ==============================================
# ä¸»ç¨‹åº
# ==============================================
if __name__ == "__main__":
    model = InceptionV3Features().to(device)

    results = []

    for gen_name, real_name in pairs:
        gen_dir = os.path.join(base_dir, gen_name)
        real_dir = os.path.join(base_dir, real_name)

        if not os.path.exists(gen_dir) or not os.path.exists(real_dir):
            print(f"âŒ æ‰¾ä¸åˆ°è·¯å¾„: {gen_dir} æˆ– {real_dir}")
            continue

        print(f"\nğŸ”¹ æ­£åœ¨è®¡ç®— FID: {gen_name} vs {real_name} ...")

        gen_imgs = load_images_from_folder(gen_dir, transform)
        real_imgs = load_images_from_folder(real_dir, transform)

        print(f"âœ… åŠ è½½å›¾åƒæ•°é‡: {len(gen_imgs)} (ç”Ÿæˆ) vs {len(real_imgs)} (çœŸå®)")

        gen_loader = DataLoader(TensorDataset(gen_imgs), batch_size=16, shuffle=False)
        real_loader = DataLoader(TensorDataset(real_imgs), batch_size=16, shuffle=False)

        gen_feats = get_features(model, gen_loader, device)
        real_feats = get_features(model, real_loader, device)

        mu1, sigma1 = np.mean(gen_feats, axis=0), np.cov(gen_feats, rowvar=False)
        mu2, sigma2 = np.mean(real_feats, axis=0), np.cov(real_feats, rowvar=False)

        fid = calculate_fid(mu1, sigma1, mu2, sigma2)
        print(f"âœ… {gen_name} vs {real_name} â†’ FID = {fid:.4f}")
        results.append((gen_name, real_name, fid))

    print("\nğŸ“Š å…¨éƒ¨ç»“æœï¼š")
    for g, r, f in results:
        print(f"   {g:10s} vs {r:10s} â†’ FID = {f:.4f}")
    # ==============================================
    # ä¿å­˜ç»“æœåˆ° txt æ–‡ä»¶
    # ==============================================
    save_dir = os.path.join(base_dir, "metrics")
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, "FID_baseline.txt")

    with open(save_path, "w", encoding="utf-8") as f:
        f.write("ğŸ“Š FID Baseline Results\n")
        f.write("=========================\n")
        for g, r, fid_value in results:
            f.write(f"{g:10s} vs {r:10s} â†’ FID = {fid_value:.4f}\n")

    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°ï¼š{save_path}")